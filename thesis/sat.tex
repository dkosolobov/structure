\chapter{SAT}
\label{chap:sat}

\section{Basic Concepts}

This section formalizes the SAT problem and introduces basic notations.

\begin{mydef}
  \emph{Boolean space} is $\mathbb{B} = \{ True, False \}$.
\end{mydef}

\begin{mydef}
  A \emph{Boolean formula} $F$ is a function of $n$ \emph{boolean variables}.
  $F : \mathbb{B}^n \rightarrow \mathbb{B}$.
\end{mydef}

\begin{mydef}
  A Boolean formula $F : \mathbb{B}^n \rightarrow \mathbb{B}$ is
  \emph{consistent} (or satisfiable) if there is an assignment of
  variables such that the formula evaluates to \emph{True}
  ($\exists u_1, \ldots u_n$ such that $F(u_1, \ldots, u_n) = True$).
  F is said to be \emph{inconsistent} (or unsatisfiable) if
  there is no such assignment.
\end{mydef}

\begin{mydef}
  Two formulas $F_1$ and $F_2$ are logically \emph{equivalent},
  $F_1 \equiv F_2$, if any satisfying assignment of one formula is
  a satisfying assignment of the other.
\end{mydef}

\begin{mydef}
  A \emph{propositional} Boolean formula is a Boolean formula that contains only
  logic operations \textbf{and} (conjunction, denoted with $\land$),
  \textbf{or} (disjunction, denoted with $\lor$) and \textbf{not}
  (negation, denoted with $\neg$).
\end{mydef}

A propositional Boolean formula is in \emph{conjunctive normal form}
(CNF), if:
\begin{itemize}
  \item It is a conjunction of \emph{clauses};
  \item Each clause is a disjunction of one more \emph{literals};
  \item A literal is an occurrence of a Boolean variable or its negation.
  If the literal is the occurrence of a variable
  then it has \emph{positive polarity}, otherwise it has \emph{negative
  polarity}.
\end{itemize}

Small letters $u, v, t, \ldots$ or small letters with indices $u_0,
u_1, \ldots$ will be used to indicate variables and literals (the
distinction will be obvious in the context). In the examples
indices $1, 2, \ldots$ will be used to indicate variables.

We will denote clauses as sets of literals $C = \{ u_1, u_2, \ldots,
u_k \}$ and formulas as a set of clauses $F = \{ C_1, C_2, \ldots,
C_m \} $.  An example of formula is
\[
F(u, v, t) = (u \lor v \lor t) \land (\neg u \lor \neg v)
\]
or as sets
\[
F = \{ \{u, v, t\}, \{\neg u, \neg v)\}\}
\]

\begin{myprop}
  A formula containing 0 clauses is consistent.
\end{myprop}

\begin{myprop}
  A formula containing an empty clause ($\emptyset \in F$) is inconsistent.
\end{myprop}


\section{Solving SAT}
\label{sec:solving-sat}

\subsection{Boolean Constraint Propagation}
\label{ssec:bcp}

Boolean constraint propagation (BCP) was introduced in
\cite{Davis:1960:CPQ:321033.321034} as a process formula
simplification.

\begin{mydef}
  \emph{Boolean constraint propagation} of a formula, $BCP(F)$, is
  the formula resulting from repeating the process of propagating
  unit clauses until a fixed point. If $\{ u \} \in F$ is a unit
  clause then propagation of literal
  $u$ is performed according to two rules:
  \begin{enumerate}
    \item $\neg u$ is removed from every clause containing it; and
    \item every clause containing literal $u$ is removed from $F$.
  \end{enumerate}
\end{mydef}

\begin{mydef}
$UP(F)$ is the set of literals propagated during $BCP(F)$.
\end{mydef}

We will denote the boolean constraint propagation of a literal $u$ in a
formula $F$ with $BCP(F, u) \equiv BCP(F \cup \{\{ u \}\})$
and similarly $UP(F, u) \equiv UP(F \cup \{\{ u \}\})$. Example:

\begin{align}
  F &= t \land \neg u \land (u \lor t \lor z) \land (u \lor v \lor \neg t \lor z) \\
  BCP(F) &= (v \lor z) \\
  UP(F) &= \{ t, \neg u \}
\end{align}

\begin{myprop}
  $F$ is consistent iff $BCP(F)$ is consistent.
\end{myprop}

\begin{myprop}[Failed literals]
  If the propagation of a literal is inconsistent then any satisfying
  assignment of $F$ must contain the negation of that literal.
  $\emptyset \in BCP(F, u) \Rightarrow F \equiv F \cup \{\neg u\}$.
\end{myprop}


\subsection{Pure Literal Rule (PL)}
\label{ssec:pl}

Pure literal rule was first described in \cite{Davis:1960:CPQ:321033.321034}
as follows:

\begin{mydef}[Pure Literal Rule]
  If a variable $u$ occurs in formula $F$ in CNF only positively, or
  if $u$ occurs only negatively, then all clauses which contain $u$
  may be deleted. The resulting formula $F'$ is inconsistent
  if and only if $F$ is. (If $F'$ is empty, then it is consistent).
  The polarity that appears in $F$ is called \emph{pure literal}.
\end{mydef}

We will denote with $PL(F)$ the formula resulted after applying
the pure literal rule on $F$ until a fixed point.


\subsection{DPLL Algorithm}
\label{ssec:dpll}

Most SAT solvers are based on the original algorithm from
\cite{Davis:1962:MPT:368273.368557}, also known as DPLL, for deciding
the satisfiability of logic formula.  The algorithm is described
by pseudo-code \ref{alg:dpll} and has four important steps:
\begin{inparaenum}[1)]
  \item verify formula;
  \item simplify formula;
  \item decide on a branching literal; and
  \item recurse.
\end{inparaenum}

Modern SAT solvers differ from DPLL in applying
stronger simplification procedures and using better
decisions heuristics. Another important step introduced in
\cite{Marques-silva99grasp:a} is restarting the search at regular
intervals and augmenting the basic search with clauses derived
from conflicts.


\begin{algorithm}
  \begin{algorithmic}
    \REQUIRE{$F$ a Boolean formula in CNF}
    \ENSURE{True if $F$ is consistent $F$}

    // 1. Check if a solution was found, or formula is inconsistent
    \IF{$F$ is a consistent set of literals}
      \PRINT Found solution
      \RETURN True
    \ENDIF
    \IF{$F$ contains an empty clause}
      \RETURN False
    \ENDIF

    // 2. Simplify formula
    \STATE $F \gets BCP(F)$ // See section \ref{sec:bcp}
    \STATE $F \gets PL(F)$  // See section \ref{sec:pl}

    // 3. Decide
    \STATE $u \gets decide(F)$

    // 4. Recurse
    \RETURN $DPLL(F \land l) \lor DPLL(F \land \neg l)$
  \end{algorithmic}

  \caption{DPLL algorithm for SAT solving}
  \label{alg:dpll}
\end{algorithm}


\section{Additional Reasoning Procedures}

This sections explains additional reasonings used in STRUCTure in
the simplification step besides the Boolean Constraint Propagation
and Pure Literal Rule from the original algorithms.

\subsection{Boolean Resolution Operator}
\label{ssec:resolution}

Many reasonings procedures discussed in the next sections are based
on \emph{resolution operator} \cite{Robinson:1965:MLB:321250.321253}
which derives an implied clause, named \emph{resolvent}, from
a pair of clauses containing a literal of opposite polarities,
called \emph{pivot}.

\begin{mydef}[Boolean Resolution]
  \label{mydef:resolution}
  Let $C = \{ u, v_1, \ldots, v_{k_v} \}$ and $D = \{ \neg u,
  t_1, \ldots, t_{k_t} \}$. The resolvent $C \otimes_{u} D$ of $C$
  and $D$ on pivot $u$ is the clause $\{v_1, \ldots, v_{k_v}, t_1,
  \ldots, t_{k_t}\}$.
\end{mydef}

\begin{mydef}[Boolean Resolution for a set of clauses]
  If $S_u$ and $S_{\neg u}$ are two sets of clauses containing
  literal $u$ and, respectively, literal $\neg u$ then:

  $$S_u \otimes_{u} S_{\neg u} = \{ C_u \otimes_{u} C_{\neg u} |
  C_u \in S_u \land C_{\neg u} \in S_{\neg u}\}$$
\end{mydef}

\begin{myprop}
  Boolean resolution preserves satisfiability. $S_u \cup S_{\neg u}
  \equiv S_u \otimes_{u} S_{\neg u}$.
\end{myprop}

\subsection{Equivalent Literals Renaming}
\label{ssec:eqlr}

Consider the formula $F = (u \lor \neg v) \land (\neg u \lor v) \land \ldots$.
If $u$ is true then $v$ must be true and similarly, if $u$ is false
then $v$ must be false. In this case $u$ and $v$ are said to be
\emph{equivalent} literals. Every occurrence of literal $v$ can be
replaced with $u$ and every occurrence of $\neg v$ can be
substituted for $\neg u$, removing $v$ from $F$.

\begin{myprop}
  A binary clause is equivalent with two implications:
  $u \lor v \equiv \neg u \rightarrow v \equiv \neg v \rightarrow u$.
\end{myprop}

\begin{mydef}
  The \emph{implication graph} of a formula $F$ is an oriented graph
  $\I_F = (V, E)$ where $V$ is the set of all literals and $E = \{(u,
  v) \in V \times V | \{\neg u, v\} \in F\}$ (E contains all implications in $F$).
\end{mydef}

Let the relation $u \rightsquigarrow v$ be true if and only if
$v$ can be reached from $u$ in $\I_F$.  If $u \rightsquigarrow v$
and $v \rightsquigarrow u$ then $u$ and $v$ are equivalent.  In the
implication graph $\I_F$ all literals in the same strongly connected
component\footnote{A component is a \emph{strongly connected}
if every node in the component can be reached from every other node}
are equivalent. The component can be be collapsed into a single
literal and all literals can be renamed to the new literal.

\begin{myprop}
  If $u \leftrightsquigarrow v$ then every occurrence of $v$ can be replaced
  with $v$. More generally, in the implication graph each strongly
  connected component can be collapsed to a single literal and, in
  the formula every literal from the component can be replaced with
  the new literal.
\end{myprop}


\subsection{Hidden Literal Addition}
\label{ssec:hla}

\emph{Hidden Literal Addition} ($HLA(F, C)$) was introduced in
\cite{mine:hjb_efficient} as a technique to enlarge a clause $C$
in a formula $F$ with new literals $L$, such that $F \equiv F \setminus \{C\} \
\cup \{ C \cup L \}$. By itself this enlargement is not useful, but it
can improve other reasoning algorithms \cite{Heule:2010:CEP:1928380.1928406, Heule_coveredclause}.

\begin{mydef}
  $HLA(F, C)$ is the unique clause resulting from repeating the following
  clause extension steps until a fixed point: if there is a literal $u_0 \in C$
  and a literal $v$ such that $\neg v \rightsquigarrow u \text{ in } \I_F$
  extend $C$ with $\neg v$, $C := C \cup \{ \neg v \}$.
\end{mydef}

\begin{myprop}
  $F \equiv F \setminus \{C\} \cup \{HLA(F, C)\}$ for $C \in F$.
\end{myprop}

To find the extension of the clause $C$, a search is performed in the
implication graph, $G_F$, starting from negation of the literals in
the clause. $HLA(F, C)$ will be the set of negations of the visited
literals.

For example, for clause $C = \{ 2, \neg 4, 3\}$
and implication graph in Figure \ref{fig:hla}
$HLA(F, C) = \{2, \neg 4, \mathbf{\neg 5, \neg 6}, 3, \mathbf{\neg 2} \}$.

\begin{figure}
  \centering
  \includegraphics[width=0.4\linewidth]{dia/hla}
  \caption{An implication graph}
  \label{fig:hla}
\end{figure}


\subsection{Hidden Tautology Elimination (HTE)}
\label{ssec:hte}

\emph{Hidden Tautology Elimination} eliminates certain clauses that
are satisfied regardless of value of an arbitrary variable. Such
clauses are redundant and can be removed from the Boolean formula
preserving its satisfiability.

\begin{mydef}
  A clause is a \emph{tautology} if it contains a literal, $u$, and its negation
  $\neg u$. A clause of length 0 is an \emph{empty clause}; a clause of length 1
  is a \emph{unit clause}; a clause of length 2 is a \emph{binary clause}. 
\end{mydef}

\begin{myprop}[TE]
  \label{myprop:removal-of-tautologies}
  A formula $F$ is equivalent with $F$ with all tautologies removed.
  $F \equiv F \setminus \{ C \in F | C \text{ is tautology}\}$.
\end{myprop}

\begin{myprop}[HTE]
  $HLA(F, C) \text{ is a tautology} \Rightarrow F \equiv F \setminus \{C\}$.
\end{myprop}

\begin{proof}
  Following from proposition \ref{myprop:removal-of-tautologies},
  if $HLA(F, C)$ is a tautology it can be removed from the formula.
  $F \equiv F \setminus \{C\} \cup \{HLA(F, C)\} \equiv F \setminus \{C\}$
\end{proof}

For example, for clause $C = \{ 2, \neg 4, 3\}$ and implication graph
in Figure \ref{fig:hla} $HLA(F, C) = \{2, \neg 4, \mathbf{\neg 5,
\neg 6}, 3, \mathbf{\neg 2} \}$.  If variable $2$ is $True$ then
$C$ is satisfied. If variable $2$ is $False$ then $3$ is $True$
($\neg 2 \rightarrow 3$) so $C$ is satisfied.


\subsection{Hyper-Unit (HUR) and Hyper-Binary (HBR) Resolutions}
\label{ssec:hbr}

\emph{Hyper-unit resolution} (HUR) \cite{Kusper02solvingthe} is
an inference rule involving multiple resolutions in which one of
the clauses is a binary. It takes $n$ binary clauses and an $n$
literals clause and produces a new unit.  Similarly \emph{hyper
binary resolution} (HBR) \cite{Bacchus03effectivepreprocessing} takes
$n$ binary clauses and an $n + 1$ literals clause and produces a
new binary.

\begin{myprop}[Hyper-unary resolution]
  If a propagation of a literal $u$ results in an empty clause then
  the negation of that literal must be true.
  $(u \rightsquigarrow \neg v_1) \land \ldots
  \land (u \rightsquigarrow \neg v_n) \land (v_1 \lor \dots \lor v_n)
  \Rightarrow \neg u$. 
\end{myprop}

\begin{myprop}[Hyper-binary resolution]
  If a propagation of a literal $u$ results in an unit clause $\{ v \}$
  then implication $u \lor v$ must be true.
  $(u \rightarrow \neg v_1) \land \ldots
  \land (u \rightarrow \neg v_n)
  \land (v_1 \lor \dots \lor v_n \lor t) \Rightarrow (\neg u \lor t)$
\end{myprop}

\cite{Bacchus03effectivepreprocessing} shows that HUR and HBR
are closely related to boolean constraint propagation.  Indeed,
propagation of literal $u$ results in literals $v_1, \ldots, v_n$
so clause $(v_1 \lor \dots \lor v_n)$ is reduced to empty clause
$\phi$ and, respectively, clause $(v_1 \lor \dots \lor v_n \lor
t)$ is reduced to unit clause $\{ t \}$. From the former we obtain
forced literal $\neg u$. From the later we obtain implication $u
\rightarrow t$.

In practice performing HUR and HBR are faster than performing BCP on
all literals. Many look-ahead SAT solvers perform a variant of BCP
\cite{Freeman:1995:IPS:220639} at every branch to discover new units
and binaries, but in STRUCTure BCP is substituted for HUR.

Algorithm \ref{alg:hyper-resolution} (see appendix
\ref{chap:algorithms}) applies hyper-unary and hyper-binary
resolutions on a CNF formula. In practice, many binary clauses
generated are redundant (e.g. two consecutive runs of hyper-binary
resolution will generate almost the same clauses) so the usefulness
of HBR is not clear and not used.


\subsection{Subsumption (SS) and Self-subsumption (SSS)}
\label{ssec:sss}

\emph{Subsumption} and \emph{self-subsumption} are two simplification
techniques introduced in \cite{Een05effectivepreprocessing}
that work well in the context of quantified boolean formulas
\cite{Biere04resolveand}.

Subsumption is the process of removing clauses that are a superset
of other clauses. The subsumed clauses are satisfied whenever
the subsuming clause is satisfied so they don't need to be part of
the formula.

\begin{myprop}[Subsumption]
  If a clause includes another clause then the former is satisfied whenever the
  later is satisfied.
  $C_1, C_2 \in F \land C_1 \subseteq C_2 \Rightarrow F \equiv F \setminus \{
  C_2 \}$
\end{myprop}

Similarly self-subsumption takes two clauses $C_1$ and $C_2$ such
that $C_1$ is almost a superset of $C_2$, except one variable which
polarity is reversed and removes that corresponding literal from
the larger clause.

\begin{myprop}[Self-subsumption]
  If a clause is almost included in another clause except one literal whose
  polarity is reversed that literal can be removed from the larger clause.
  $(\neg u \lor v_1 \lor \ldots \lor v_i \lor v_{i+1} \lor \ldots \lor v_n)
    \land (u \lor v_1 \lor \ldots \lor v_i)
    \Rightarrow (v_1 \lor \ldots \lor v_i \lor v_{i+1} \lor \ldots \lor v_n)$
\end{myprop}


\subsection{XOR Gates Extraction}
\label{ssec:xor-extraction}

Many encoded circuits have XOR and XNOR gates which are equation
in $\mathbb{Z}_2$ (see Table \ref{tbl:xor-formula}). The method
to encode an X(N)OR gate into CNF clauses is described in
\cite{Roy_restoringcircuit}.

\begin{table}
  \centering
  \framebox{
    \begin{tabular}{ll}
      \emph{Gate type} & \emph{Boolean formula} \\
      \hline
      \text{XOR} & $0 = u_0 \oplus \ldots \oplus u_{n-1}$ \\
      \text{XNOR} & $1 = u_0 \oplus \ldots \oplus u_{n-1}$ \\
    \end{tabular}
  }

  \caption{XOR/XNOR gates}
  \label{tbl:xor-formula}
\end{table}

Encoding an XOR gate with $n$ inputs and one output in a CNF
formula requires $2^n$ clauses of length $n + 1$, one literal
for each input or output.  Every clause contains an odd number of
negations resulting in $2^n$ different combinations. Encoding an
XNOR gate is similar, except that clauses will contain an even
number of negations.

Negating an input (i.e., one of the literals) in the X(N)OR gate is
equivalent with reversing the type of gate (XOR $\leftrightarrow$
XNOR). Specifying a gate will use only variables without negations
and whether it is an XOR or an XNOR gate.  Example of encodings are
given in table \ref{tbl:xor-encoding}.

Extracting X(N)OR gates shorten the formula considerably. 32
clauses of 6 literals each will be replaced by a single gate of 6
variables. However, many reasoning algorithms ignore X(N)OR gates,
which makes the algorithms less powerful.

\begin{table}
  \centering
  \framebox{
    \begin{tabular}{ll}
      \emph{X(N)OR gate} & \emph{Encoding} \\
      \hline
      $0 = u \oplus v$ & $(\neg u \lor v) \land (u \lor \neg v)$ \\
      $1 = u \oplus v \oplus t$ & $(u \lor v \lor t) \land (\neg u \lor \neg v \lor t) \land
      (\neg u \lor v \lor \neg t) \land (u \lor \neg v \lor \neg t)$ 
    \end{tabular}
  }

  \caption{Example of CNF encodings of XOR and XNOR gates}
  \label{tbl:xor-encoding}
\end{table}


\begin{mydef}[Suming X(N)OR gates]
  \label{myprop:xor-sum}
  If $C_0: a = u_0 \oplus \ldots \oplus u_{n-1}$ and $C_1: b =
  v_0 \oplus \ldots \oplus v_{m-1}$ are two X(N)OR gates let $C_0
  \bigoplus C_1: a \oplus b = u_0 \oplus \ldots \oplus u_{n-1}
  \oplus v_0 \oplus \ldots \oplus v_{m-1}$. \footnote{Note that
  under $\mathbb{Z}_2$, $z \oplus z = 0$, so if a variable appears
  twice in the right side of the equation it can be removed.}
\end{mydef}

\begin{myprop}
  Let $C_0, C_1 \in F$ be two X(N)OR gates. $F \equiv F \setminus \{C_1\} \cup
  \{C_0 \bigoplus C_1\}$.
\end{myprop}

According to the last proposition tahe X(N)OR gates in a
formula $F$ can be handled as a system of linear equations in
$\mathbb{Z}_2$. Multiple X(N)OR gates can be summed together to
knock out variables.

The reverse of \ref{myprop:xor-sum} is also true and in fact is
used to split large XOR gates which otherwise would generate too
many disjunctive clauses. If $a = u_0 \oplus \ldots \oplus u_{n-1}$
where $a \in \{0, 1\}$ is a X(N)OR gate, then an extra variable,
$z$, can be used to split the gate in two smaller X(N)OR gates $a =
u_0 \oplus \ldots \oplus u_{k} \oplus z \land 0 = z \oplus u_{k +
1} \oplus \ldots \oplus u_{n}$.


\subsection{Dependent Variable Removal (DVR)}
\label{ssec:dvr}

\emph{Dependent Variable Removal} is a technique introduced in
\cite{mine:march} which simplifies a Boolean formula by removing
redundant variables from the system of $\mathbb{Z}_2$ equations
made of X(N)OR gates.

\begin{mydef}
  A variable is called \emph{dependent} with respect to $F$ if it
  appears only in XOR gates.
\end{mydef}

\begin{myprop}[DVR]
  \label{myprop:dvr-single}
  Let $u$ be a variable that appears in exactly one XOR gate $C
  \in F$. If $F \setminus \{C\}$ is consistent if and only if $F$
  is consistent.
\end{myprop}

\begin{proof}
  \begin{enumerate}
    \item $F \Rightarrow F \setminus \{C\}$. Any satisfying
    assignment of $F$ is a satisfying assignment of $F \setminus
    \{C\}$. 
    \item $F \setminus \{C\} \Rightarrow F$.  Given that $C$ is a XOR
    gate, then $u$ can be assigned from a satisfying assignment of
    $F \setminus \{C\}$ such that $C$ is satisfied $\Rightarrow F$
    is satisfied.
  \end{enumerate}
\end{proof}


Let $u$ be a dependent variable that appears in $k + 1$ XOR gates
$C_0, ..., C_k \in F$. Let $C'_i = C_i \bigoplus C_0$ for $i = 1,
\ldots, k$.  Applying proposition \ref{myprop:xor-sum} repeatedly we
obtain $F \equiv F' = F \setminus \{C_{1}, ..., C_k\} \cup \{C'_{1},
..., C'_k\}$. This is basically a single step from Gaussian
elimination applied on a system of equations in $\mathbb{Z}_2$.

Furthermore, from proposition \ref{myprop:dvr-single}, $C_0$ can be
removed from $F'$ preserving satisfiability. Applying this algorithm
repeatedly removes all dependent variables.


\subsection{Variable Elimination (VE)}
\label{ssec:ve}

\emph{Variable elimination} \cite{Davis:1960:CPQ:321033.321034}
was part of the original algorithm for SAT solving with exponential
space complexity, but it was replaced by DPLL which has
polynomial space, but exponential time complexity. However, in
\cite{Subbarayan04niver:non,Een05effectivepreprocessing} it was
shown that VE combined with SS and SSS can be highly effective in
the context of industrial applications if it is applied only on
variables for which the formula has a limited increase in size.

Variable elimination is based on the Boolean resolution operator
(\ref{ssec:resolution}). If $S_u$ is the set of clauses in $F$
containing literal $u$ and, similarly, $S_{\neg u}$ is the set of clauses in $F$
containing literal ${\neg u}$ then $F$ is substituted for
$F \setminus S_u \setminus S_{\neg u} \cup S_u \otimes_{u} S_{\neg u}$.

In STRUCTure variables selected for elimination are chosen such that
the number of literals in all clauses $S_u \otimes_{u} S_{\neg u}$
is at most one more than literals in $S_u$ and $S_{\neg u}$.


\subsection{Blocked Clause Elimination (BCE)}
\label{ssec:bce}

\emph{Blocked clauses} are a class of redundant clauses
that can be added to \cite{Kullmann:1999:NMD:312269.312271} or
removed from \cite{Jarvisalo_blockedclause} a formula preserving
satisfiability. Blocked clause elimination perform powerful
simplification of CNF circuit encodings.

\begin{mydef}[Blocked clause]
  A clause $C$ is called \emph{blocked}
  for literal $l$ with respect to formula $F$ if and only if $\forall
  C' \in F$ the resolvent of $C$ and $C'$ is a tautology.
\end{mydef}


In \cite{Jarvisalo_blockedclause} the authors suggest that VE might
improve BCE (see subsection \ref{ssec:bce}), but I found no significant
difference in performance if the order is reversed (see appendix
\ref{chap:bce-ve}).

STRUCTure performs a stronger version of BCE in which the clause
is first extended with literals hidden by the blocking literal
(see subsection \ref{ssec:hla}) \cite{Heule_coveredclause}.
